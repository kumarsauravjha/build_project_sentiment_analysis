{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56779307",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome to this interactive Jupyter notebook on Sentiment Analysis using product reviews. This exercise will help you learn how to process text data, analyze sentiment, and apply basic NLP techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca7c75",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Ensure you have the necessary libraries installed and imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ceb267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: textblob in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: click in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (from nltk) (2024.4.28)\n",
      "Requirement already satisfied: tqdm in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sam/.pyenv/versions/3.10.13/envs/build/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/sam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install nltk scikit-learn textblob\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5edd0f",
   "metadata": {},
   "source": [
    "## Product Reviews\n",
    "Below is an array of positive and negative product reviews that we will analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4df690",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['I absolutely love this product! Highly recommend to everyone.', \"Fantastic quality! I'm very happy with my purchase.\", 'This is the best thing I have bought in a long time!', 'Completely satisfied with the product and service.', 'Five stars, will buy again!', 'This product does exactly what it says, fantastic!', 'Incredible performance and very easy to use.', 'I am so pleased with this purchase, worth every penny!', 'Great value for money and quick delivery.', 'The best on the market, hands down!', 'Such a great purchase, very pleased!', 'Product is of high quality and super durable.', 'Surpassed my expectations, absolutely wonderful!', 'This is amazing, I love it so much!', 'The product works wonderfully and is well made.', 'Not what I expected, quite disappointed.', 'The quality is not as advertised, very upset.', 'This was a waste of money, would not buy again.', 'Poor quality and did not meet my expectations.', \"I regret buying this, it's awful.\", 'Terrible product, do not waste your money!', 'Very unsatisfied with the purchase, it broke within a week.', 'Not worth the price, very misleading.', \"The worst purchase I've ever made!\", \"Disappointed with the product, it's not good at all.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d0536e",
   "metadata": {},
   "source": [
    "## Text Cleaning Exercise\n",
    "Clean the text data by converting to lowercase, removing punctuation, and filtering out stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc51d1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely love product highly recommend everyone', 'fantastic quality happy purchase', 'best thing bought long time', 'completely satisfied product service', 'five stars buy', 'product exactly says fantastic', 'incredible performance easy use', 'pleased purchase worth every penny', 'great value money quick delivery', 'best market hands', 'great purchase pleased', 'product high quality super durable', 'surpassed expectations absolutely wonderful', 'amazing love much', 'product works wonderfully well made', 'expected quite disappointed', 'quality advertised upset', 'waste money would buy', 'poor quality meet expectations', 'regret buying awful', 'terrible product waste money', 'unsatisfied purchase broke within week', 'worth price misleading', 'worst purchase ever made', 'disappointed product good']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_text(reviews):\n",
    "    cleaned_reviews = []\n",
    "    for review in reviews:\n",
    "        # Tokenize the review\n",
    "        # Remove punctuation and stopwords\n",
    "        cleaned_reviews.append(' '.join(cleaned_tokens))\n",
    "    return cleaned_reviews\n",
    "\n",
    "# Clean the reviews\n",
    "cleaned_reviews = clean_text(reviews)\n",
    "print(cleaned_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7328509",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Exercise\n",
    "Perform sentiment analysis using simple word counting. Identify positive and negative words, and classify the reviews based on the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba31036a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('absolutely love product highly recommend everyone', 'Positive')\n",
      "('fantastic quality happy purchase', 'Positive')\n",
      "('best thing bought long time', 'Positive')\n",
      "('completely satisfied product service', 'Positive')\n",
      "('five stars buy', 'Negative')\n",
      "('product exactly says fantastic', 'Positive')\n",
      "('incredible performance easy use', 'Positive')\n",
      "('pleased purchase worth every penny', 'Positive')\n",
      "('great value money quick delivery', 'Positive')\n",
      "('best market hands', 'Positive')\n",
      "('great purchase pleased', 'Positive')\n",
      "('product high quality super durable', 'Positive')\n",
      "('surpassed expectations absolutely wonderful', 'Positive')\n",
      "('amazing love much', 'Positive')\n",
      "('product works wonderfully well made', 'Positive')\n",
      "('expected quite disappointed', 'Negative')\n",
      "('quality advertised upset', 'Negative')\n",
      "('waste money would buy', 'Negative')\n",
      "('poor quality meet expectations', 'Negative')\n",
      "('regret buying awful', 'Negative')\n",
      "('terrible product waste money', 'Negative')\n",
      "('unsatisfied purchase broke within week', 'Negative')\n",
      "('worth price misleading', 'Negative')\n",
      "('worst purchase ever made', 'Negative')\n",
      "('disappointed product good', 'Negative')\n",
      "Positive Reviews: 14\n",
      "Negative Reviews: 11\n",
      "Overall Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "positive_words = ['love', 'fantastic', 'best', 'incredible', 'pleased', 'great', 'amazing', 'high', 'wonderful', 'satisfied']\n",
    "negative_words = ['disappointed', 'waste', 'poor', 'regret', 'terrible', 'unsatisfied', 'broke', 'worst', 'not']\n",
    "\n",
    "def analyze_sentiment(reviews):\n",
    "    results = []\n",
    "    for review in reviews:\n",
    "        # Get count of positive and negative words in the review\n",
    "        # Determine sentiment as positive or negative\n",
    "        pass\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Analyze the sentiment of cleaned reviews\n",
    "sentiment_results = analyze_sentiment(cleaned_reviews)\n",
    "for result in sentiment_results:\n",
    "    print(result)\n",
    "    \n",
    "#TODO: Are the reviews mostly positive or negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af6c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I absolutely love this product! Highly recommend to everyone. - Sentiment: 0.3925\n",
      "Fantastic quality! I'm very happy with my purchase. - Sentiment: 0.75\n",
      "This is the best thing I have bought in a long time! - Sentiment: 0.46875\n",
      "Completely satisfied with the product and service. - Sentiment: 0.5\n",
      "Five stars, will buy again! - Sentiment: 0.0\n",
      "This product does exactly what it says, fantastic! - Sentiment: 0.375\n",
      "Incredible performance and very easy to use. - Sentiment: 0.7316666666666667\n",
      "I am so pleased with this purchase, worth every penny! - Sentiment: 0.4375\n",
      "Great value for money and quick delivery. - Sentiment: 0.5666666666666667\n",
      "The best on the market, hands down! - Sentiment: 0.4027777777777778\n",
      "Such a great purchase, very pleased! - Sentiment: 0.5375\n",
      "Product is of high quality and super durable. - Sentiment: 0.24666666666666665\n",
      "Surpassed my expectations, absolutely wonderful! - Sentiment: 1.0\n",
      "This is amazing, I love it so much! - Sentiment: 0.45\n",
      "The product works wonderfully and is well made. - Sentiment: 1.0\n",
      "Not what I expected, quite disappointed. - Sentiment: -0.425\n",
      "The quality is not as advertised, very upset. - Sentiment: 0.2\n",
      "This was a waste of money, would not buy again. - Sentiment: -0.2\n",
      "Poor quality and did not meet my expectations. - Sentiment: -0.4\n",
      "I regret buying this, it's awful. - Sentiment: -1.0\n",
      "Terrible product, do not waste your money! - Sentiment: -0.4375\n",
      "Very unsatisfied with the purchase, it broke within a week. - Sentiment: 0.2\n",
      "Not worth the price, very misleading. - Sentiment: 0.02500000000000001\n",
      "The worst purchase I've ever made! - Sentiment: -1.0\n",
      "Disappointed with the product, it's not good at all. - Sentiment: -0.55\n",
      "Average Sentiment: 0.17086111111111113\n",
      "Overall Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentiments = []\n",
    "\n",
    "for review in reviews:\n",
    "    blob = TextBlob(review)\n",
    "    # Get the sentiment score (polarity) of the review\n",
    "    # Classify the sentiment as positive, negative or neutral\n",
    "    # Append the sentiment score to the sentiments list\n",
    "    \n",
    "\n",
    "for i, review in enumerate(reviews):\n",
    "    print(f'{review} - Sentiment: {sentiments[i]}')\n",
    "    \n",
    "#TODO: Calculate the average sentiment score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1eeb2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this exercise! You've learned how to clean text data and perform basic sentiment analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
